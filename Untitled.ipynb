{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "e50acff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "310b61b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(y_true, y_pred):\n",
    "    y_true_list = list(y_true)\n",
    "    y_dif = y_true_list - y_pred\n",
    "    y_num = len(y_true_list)\n",
    "    cnt = y_num\n",
    "    ret = 0\n",
    "    for i in range(y_num):\n",
    "        if y_true_list[i] != 0:\n",
    "            ret += abs(y_dif[i]/y_true_list[i])\n",
    "        else:\n",
    "            cnt = cnt-1\n",
    "    return (ret/cnt)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "9524453a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class forecast:\n",
    "    def __init__(self, RawData, training_size):\n",
    "        self.data = RawData\n",
    "        self.size = training_size\n",
    "        train_data, test_data = train_test_split(RawData, train_size = training_size, random_state=0, shuffle=False)\n",
    "        self.x_train = train_data.iloc[:,1:]\n",
    "        self.y_train = train_data.iloc[:,0]\n",
    "        self.x_test = test_data.iloc[:,1:]\n",
    "        self.y_test = test_data.iloc[:,0]\n",
    "\n",
    "    def linear_regression(self):\n",
    "        self.model = LinearRegression()\n",
    "        self.model.fit(self.x_train,self.y_train)\n",
    "\n",
    "    def support_vector_regressor(self):\n",
    "        dif = 1\n",
    "        best_score = 0\n",
    "        '''for gamma in ['auto', 'scale']:\n",
    "            for c in [*np.arange(0.1, 1, 0.1), *np.arange(1, 30, 1), *np.arange(30, 100, 5), *np.arange(100, 1000, 10)]:\n",
    "                cls = SVR(gamma=gamma,C=c)\n",
    "                cls.fit(self.x_train,self.y_train)\n",
    "                score = cls.score(self.x_test,self.y_test)\n",
    "                if cls.score(self.x_train, self.y_train)>0 and score>0 and np.abs(cls.score(self.x_train, self.y_train)-score < dif):\n",
    "                    dif = np.abs(cls.score(self.x_train, self.y_train)-score)\n",
    "                    best_score = cls.score(self.x_train, self.y_train)\n",
    "                    test_score = score\n",
    "                    best_parameters = {'gamma':gamma,\"C\":c}\n",
    "                elif cls.score(self.x_train, self.y_train)>best_score:\n",
    "                    best_score = cls.score(self.x_train, self.y_train)\n",
    "                    test_score = score\n",
    "                    best_parameters = {'gamma':gamma,\"C\":c}\n",
    "        cls = SVR(**best_parameters)'''\n",
    "        parameters = {\n",
    "            'kernel':['rbf'], \n",
    "            'C':[*np.arange(0.1, 1, 0.1), *np.arange(1, 30, 1), *np.arange(30, 100, 5), *np.arange(100, 1000, 10)], \n",
    "            'gamma':['auto', 'scale']\n",
    "        }\n",
    "        model = SVR()\n",
    "        cls = GridSearchCV(model, parameters, n_jobs=-1)\n",
    "        cls.fit(self.x_train, self.y_train)\n",
    "        self.model = cls\n",
    "\n",
    "    def random_forest_regressor(self):\n",
    "        dif = 1\n",
    "        best_score = 0\n",
    "        for n_estimators in range(1,501):\n",
    "            rf = RandomForestRegressor(n_estimators=n_estimators,random_state=0)\n",
    "            rf.fit(self.x_train,self.y_train)\n",
    "            score = rf.score(self.x_test,self.y_test)\n",
    "            if rf.score(self.x_train, self.y_train)>0 and score>0 and np.abs(rf.score(self.x_train, self.y_train)-score < dif):\n",
    "                dif = np.abs(rf.score(self.x_train, self.y_train)-score)\n",
    "                best_score = rf.score(self.x_train, self.y_train)\n",
    "                test_score = score\n",
    "                best_parameters = {\"n_estimators\": n_estimators}\n",
    "            elif rf.score(self.x_train, self.y_train)>best_score:\n",
    "                best_score = rf.score(self.x_train, self.y_train)\n",
    "                test_score = score\n",
    "                best_parameters = {\"n_estimators\": n_estimators}      \n",
    "        rf = RandomForestRegressor(**best_parameters)\n",
    "        rf.fit(self.x_train, self.y_train)\n",
    "        self.model = rf\n",
    "\n",
    "    def Adaboost(self):\n",
    "        err = 110.0\n",
    "        best_parameters = []\n",
    "        for l_type in ['exponential', 'linear', 'square']:\n",
    "            for depth in range(1, 9):\n",
    "                for n_est, learn_rate in [(50, 1.0), (100, 0.9), (300, 0.9), (500, 0.9)]:\n",
    "                    adb = AdaBoostRegressor(base_estimator = tree.DecisionTreeRegressor(max_depth =depth),\n",
    "                                    n_estimators = n_est,\n",
    "                                    learning_rate = learn_rate,\n",
    "                                    loss = l_type,\n",
    "                                    random_state = 1\n",
    "                                    )\n",
    "                    adb.fit(self.x_train, self.y_train)\n",
    "                    trainy_pred = adb.predict(self.x_train)\n",
    "                    train_mape = mape(self.y_train, trainy_pred)\n",
    "                    \n",
    "                    adb.fit(self.x_test, self.y_test)\n",
    "                    testy_pred = adb.predict(self.x_test)\n",
    "                    test_mape = mape(self.y_test, testy_pred) \n",
    "                    if abs(train_mape - test_mape) < err:\n",
    "                        best_parameters = [l_type, depth, n_est, learn_rate]\n",
    "\n",
    "        self.model = AdaBoostRegressor(base_estimator = tree.DecisionTreeRegressor(max_depth = best_parameters[1]),\n",
    "                                    n_estimators = best_parameters[2],\n",
    "                                    learning_rate = best_parameters[3],\n",
    "                                    loss = best_parameters[0],\n",
    "                                    random_state = 1\n",
    "                                    )\n",
    "        self.model.fit(self.x_train, self.y_train)\n",
    "        \n",
    "    def forecast_result(self, NewData):\n",
    "        y_pred = self.model.predict(NewData)\n",
    "        y_pred = pd.DataFrame(y_pred, columns=['Predicted_Y'])\n",
    "        NewData = NewData.reset_index(drop=True)\n",
    "        PredictData = y_pred.join(NewData)\n",
    "        return PredictData\n",
    "        \n",
    "    def error_result(self, model):\n",
    "        if(model=='linear'):\n",
    "            self.linear_regression()\n",
    "        elif(model=='svr'):\n",
    "            self.support_vector_regressor()\n",
    "        elif(model=='rmf'):\n",
    "            self.random_forest_regressor()\n",
    "        elif(model=='ada'):  \n",
    "            self.Adaboost()\n",
    "        y_train_pred = self.model.predict(self.x_train)\n",
    "        training_MAPE = round(mape(self.y_train, y_train_pred), 4)\n",
    "        y_test_pred = self.model.predict(self.x_test)\n",
    "        testing_MAPE =  round(mape(self.y_test, y_test_pred), 4)\n",
    "        return [training_MAPE, testing_MAPE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "abe13546",
   "metadata": {},
   "outputs": [],
   "source": [
    "class output(forecast):\n",
    "    def error_chart(self):\n",
    "        error_list = [self.error_result('linear'), self.error_result('svr'), self.error_result('rmf'), self.error_result('ada')]\n",
    "        df = pd.DataFrame (error_list, columns = ['training', 'testing'], index = ['linear regression', 'support vector regression', 'random forest', 'adaboost'])\n",
    "        self.good = []\n",
    "        for i in error_list:\n",
    "            if (np.abs(i[1]-i[0])<=5 and i[0]<=15 and i[1]<=10):\n",
    "                if(error_list.index(i)==0):\n",
    "                    self.good.append('linear')\n",
    "                elif error_list.index(i)==1:\n",
    "                    self.good.append('svr')\n",
    "                elif error_list.index(i)==2:\n",
    "                    self.good.append('rmf')\n",
    "                else:\n",
    "                    self.good.append('ada')\n",
    "        return df\n",
    "    \n",
    "    def bar_chart(self, df):\n",
    "        fig = df.plot(kind='bar', stacked=False,\n",
    "            #color=['r', 'b'],\n",
    "            rot=0, title='MAPE').get_figure()\n",
    "        fig.savefig('plot.png')\n",
    "\n",
    "#if __name__=='__main__':\n",
    "#    svr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "f602dc04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X13</th>\n",
       "      <th>X14</th>\n",
       "      <th>X15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>815</td>\n",
       "      <td>0.063250</td>\n",
       "      <td>14665</td>\n",
       "      <td>0.075850</td>\n",
       "      <td>7906</td>\n",
       "      <td>0.080300</td>\n",
       "      <td>95.710000</td>\n",
       "      <td>79.387500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>3395</td>\n",
       "      <td>0.109725</td>\n",
       "      <td>8931</td>\n",
       "      <td>0.061575</td>\n",
       "      <td>4952</td>\n",
       "      <td>0.075550</td>\n",
       "      <td>91.030000</td>\n",
       "      <td>75.512500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>5735</td>\n",
       "      <td>0.147675</td>\n",
       "      <td>9160</td>\n",
       "      <td>0.103550</td>\n",
       "      <td>9749</td>\n",
       "      <td>0.148375</td>\n",
       "      <td>97.570000</td>\n",
       "      <td>79.055000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>6359</td>\n",
       "      <td>0.235300</td>\n",
       "      <td>12403</td>\n",
       "      <td>0.106050</td>\n",
       "      <td>15530</td>\n",
       "      <td>0.191550</td>\n",
       "      <td>91.272500</td>\n",
       "      <td>75.765000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>5312</td>\n",
       "      <td>0.127825</td>\n",
       "      <td>9070</td>\n",
       "      <td>0.090975</td>\n",
       "      <td>9936</td>\n",
       "      <td>0.113150</td>\n",
       "      <td>97.265000</td>\n",
       "      <td>79.555000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18</td>\n",
       "      <td>4560</td>\n",
       "      <td>0.107150</td>\n",
       "      <td>8884</td>\n",
       "      <td>0.105000</td>\n",
       "      <td>11012</td>\n",
       "      <td>0.122375</td>\n",
       "      <td>93.537500</td>\n",
       "      <td>74.192500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>25</td>\n",
       "      <td>3756</td>\n",
       "      <td>0.186450</td>\n",
       "      <td>6457</td>\n",
       "      <td>0.149750</td>\n",
       "      <td>18234</td>\n",
       "      <td>0.190700</td>\n",
       "      <td>90.407500</td>\n",
       "      <td>71.972500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>18</td>\n",
       "      <td>4814</td>\n",
       "      <td>0.090500</td>\n",
       "      <td>617</td>\n",
       "      <td>0.063650</td>\n",
       "      <td>17436</td>\n",
       "      <td>0.076450</td>\n",
       "      <td>96.160000</td>\n",
       "      <td>78.615000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16</td>\n",
       "      <td>3986</td>\n",
       "      <td>0.121525</td>\n",
       "      <td>522</td>\n",
       "      <td>0.069425</td>\n",
       "      <td>16430</td>\n",
       "      <td>0.098750</td>\n",
       "      <td>93.405000</td>\n",
       "      <td>73.787500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>24</td>\n",
       "      <td>3568</td>\n",
       "      <td>0.161475</td>\n",
       "      <td>4686</td>\n",
       "      <td>0.084250</td>\n",
       "      <td>19744</td>\n",
       "      <td>0.146975</td>\n",
       "      <td>96.357500</td>\n",
       "      <td>82.987500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>28</td>\n",
       "      <td>4512</td>\n",
       "      <td>0.249125</td>\n",
       "      <td>9780</td>\n",
       "      <td>0.150850</td>\n",
       "      <td>17781</td>\n",
       "      <td>0.243725</td>\n",
       "      <td>88.922500</td>\n",
       "      <td>75.497500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>18</td>\n",
       "      <td>1670</td>\n",
       "      <td>0.052700</td>\n",
       "      <td>12309</td>\n",
       "      <td>0.076375</td>\n",
       "      <td>7109</td>\n",
       "      <td>0.122825</td>\n",
       "      <td>96.792500</td>\n",
       "      <td>82.625000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>27</td>\n",
       "      <td>2321</td>\n",
       "      <td>0.157832</td>\n",
       "      <td>13143</td>\n",
       "      <td>0.133335</td>\n",
       "      <td>16424</td>\n",
       "      <td>0.162422</td>\n",
       "      <td>97.366726</td>\n",
       "      <td>86.697738</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20</td>\n",
       "      <td>943</td>\n",
       "      <td>0.109704</td>\n",
       "      <td>8066</td>\n",
       "      <td>0.074103</td>\n",
       "      <td>16137</td>\n",
       "      <td>0.082240</td>\n",
       "      <td>96.660863</td>\n",
       "      <td>87.931696</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>17</td>\n",
       "      <td>3406</td>\n",
       "      <td>0.087714</td>\n",
       "      <td>7378</td>\n",
       "      <td>0.064838</td>\n",
       "      <td>11666</td>\n",
       "      <td>0.078513</td>\n",
       "      <td>94.677113</td>\n",
       "      <td>89.286696</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Y    X1        X2     X3        X4     X5        X6        X13  \\\n",
       "0   20   815  0.063250  14665  0.075850   7906  0.080300  95.710000   \n",
       "1   15  3395  0.109725   8931  0.061575   4952  0.075550  91.030000   \n",
       "2   20  5735  0.147675   9160  0.103550   9749  0.148375  97.570000   \n",
       "3   32  6359  0.235300  12403  0.106050  15530  0.191550  91.272500   \n",
       "4   19  5312  0.127825   9070  0.090975   9936  0.113150  97.265000   \n",
       "5   18  4560  0.107150   8884  0.105000  11012  0.122375  93.537500   \n",
       "6   25  3756  0.186450   6457  0.149750  18234  0.190700  90.407500   \n",
       "7   18  4814  0.090500    617  0.063650  17436  0.076450  96.160000   \n",
       "8   16  3986  0.121525    522  0.069425  16430  0.098750  93.405000   \n",
       "9   24  3568  0.161475   4686  0.084250  19744  0.146975  96.357500   \n",
       "10  28  4512  0.249125   9780  0.150850  17781  0.243725  88.922500   \n",
       "11  18  1670  0.052700  12309  0.076375   7109  0.122825  96.792500   \n",
       "12  27  2321  0.157832  13143  0.133335  16424  0.162422  97.366726   \n",
       "13  20   943  0.109704   8066  0.074103  16137  0.082240  96.660863   \n",
       "14  17  3406  0.087714   7378  0.064838  11666  0.078513  94.677113   \n",
       "\n",
       "          X14  X15  \n",
       "0   79.387500    1  \n",
       "1   75.512500    1  \n",
       "2   79.055000    1  \n",
       "3   75.765000    1  \n",
       "4   79.555000    1  \n",
       "5   74.192500    1  \n",
       "6   71.972500    1  \n",
       "7   78.615000    1  \n",
       "8   73.787500    1  \n",
       "9   82.987500    1  \n",
       "10  75.497500    1  \n",
       "11  82.625000    1  \n",
       "12  86.697738    1  \n",
       "13  87.931696    1  \n",
       "14  89.286696    1  "
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RDL = pd.read_excel(\"/Users/moca_lucy/Documents/大學/專題/RDL_AlCu/RDL_biweekly+four-weekly+monthly.xlsx\", sheet_name=\"Four-weekly\", header=0)\n",
    "RDL.drop([\"Unnamed: 11\", \"Four-week\"], axis=1, inplace=True)\n",
    "cols = RDL.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "RDL = RDL[cols]\n",
    "RDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "2e6236a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = output(RDL, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "1000400e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cls.error_chart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "d10b1889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cls.bar_chart(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "4833ad60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svr', 'rmf']"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls.good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7f158fda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.4064, 8.0535]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls.error_result('rmf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7b7d3dd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.3659, 14.628]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls.error_result('linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9f203f08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5263, 10.4781]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls.error_result('ada')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca51dad2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
