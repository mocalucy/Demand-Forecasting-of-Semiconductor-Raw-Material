{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "from sklearn.svm import SVR\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RDL = pd.read_excel(\"D:/school/專題/RDL_AlCu/Raw_data_summary_table_RDL_AlCu.xlsx\", sheet_name=\"Daily\", header=2, index_col=3)\n",
    "x = [0, 1, 2]\n",
    "RDL.drop(RDL.columns[x], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = RDL[1:337]\n",
    "testdata = RDL[337:]\n",
    "x_columns = [\"X1\", \"X2\", \"X3\", \"X4\", \"X5\", \"X6\", \"X13'\", \"X14'\", \"X15\"]\n",
    "x_train = traindata[x_columns]\n",
    "traindata\n",
    "y_train = traindata[\"Y\"]\n",
    "x_test = testdata[x_columns]\n",
    "y_test = testdata[\"Y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = SVR(kernel=\"linear\", C=0.2, gamma=0.125)\n",
    "cls.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the test score of SVR:-0.280\n"
     ]
    }
   ],
   "source": [
    "print(\"the test score of SVR:{:.3f}\".format(cls.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'kernel': ('linear', 'rbf'), 'C': [1, 2, 4], 'gamma': [0.125, 0.25, 0.5, 1, 2, 4]}\n",
    "clf = GridSearchCV(cls, param_grid=parameters)\n",
    "grid_search = clf.fit(x_train, y_train)\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gammas = np.logspace(-2, 1)\n",
    "#gammas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_SVR_rbf(*data):\n",
    "    x_train, x_test, y_train, y_test = data\n",
    "    gammas = np.logspace(-2, 1)\n",
    "    gammas\n",
    "    train_scores = []\n",
    "    test_scores = []\n",
    "    for gamma in gammas:\n",
    "        clst = SVR(gamma=gamma, kernel='rbf')\n",
    "        clst.fit(x_train, y_train)\n",
    "        train_scores.append(clst.score(x_train, y_train))\n",
    "        test_scores.append(clst.score(x_test, y_test))\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    ax.plot(gammas, train_scores, label=\"Training scores\", marker='o')\n",
    "    ax.plot(gammas, test_scores, label=\"Test scores\", marker='+')\n",
    "    ax.set_xlabel(\"gamma\")\n",
    "    ax.set_ylabel(\"score value\")\n",
    "    ax.set_ylim(-1, 1.)\n",
    "    ax.legend(loc=\"best\", framealpha=0.5)\n",
    "    ax.set_title(\"SVR_RBF_gamma\")\n",
    "    plt.show()\n",
    "    #x_train, x_test, y_train, y_test = load_data_diabetes()\n",
    "    \n",
    "#test_SVR_rbf(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svr_predict = cls.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true-y_pred)/y_true))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table(lm, x, y, w):\n",
    "    y_pred = lm.predict(x)\n",
    "    y_true = y\n",
    "   # print(y_true[190])\n",
    "    #print(np.where(np.isnan(y_pred)))\n",
    "    #print(y_pred, y_true)\n",
    "    MAE = round(metrics.mean_absolute_error(y_true, y_pred), 4)\n",
    "    #print(metrics.mean_absolute_error(y_true, y_pred))\n",
    "    MSE = round(metrics.mean_squared_error(y_true, y_pred), 4)\n",
    "    RMSE = round(np.sqrt(metrics.mean_squared_error(y_true, y_pred)), 4)\n",
    "    try:\n",
    "        MAPE =  str(round(mape(y_true, y_pred), 4))+'%'\n",
    "    except ZeroDivisionError:\n",
    "        MAPE = \"NAN\"\n",
    "    errortype = [\"MAE\", \"MSE\", \"RMSE\", \"MAPE\"]\n",
    "    error = [MAE, MSE, RMSE, MAPE]\n",
    "    #print(error)\n",
    "    if w == \"train\":\n",
    "        error_dict = {\" \":errortype, \"training\":error}\n",
    "    elif w == \"test\":\n",
    "        error_dict = {\" \":errortype, \"testing\":error}\n",
    "    #error_dict = {\" \":errortype, \"誤差分析\":error}\n",
    "    pd.options.display.float_format = '{:.4f}'.format\n",
    "    df = pd.DataFrame(error_dict)\n",
    "    df = df.set_index(\" \").rename_axis(None)\n",
    "    #print(df)\n",
    "    return df\n",
    "\n",
    "df1 = table(cls, x_train, y_train, \"train\")\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = table(cls, x_test, y_test, \"test\")\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
